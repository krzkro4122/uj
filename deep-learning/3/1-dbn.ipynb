{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Belief Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Layer, Flatten\n",
    "from keras.optimizers import AdamW\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test)  = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "x_test = x_test.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RBM layer\n",
    "class RBM(Layer):\n",
    "    def __init__(self, units):\n",
    "        super(RBM, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.units,),\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        h = tf.nn.sigmoid(tf.matmul(inputs, self.w) + self.b)\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DBN Model\n",
    "model = Sequential([\n",
    "    RBM(256),  # First RBM layer\n",
    "    RBM(64),    # Second RBM layer\n",
    "    Dense(784, activation='sigmoid'),  # Adding a dense layer to map back to original dimension\n",
    "    Flatten(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(learning_rate=1e-4)\n",
    "loss_function = BinaryCrossentropy(\n",
    "    from_logits=False,\n",
    "    label_smoothing=0.0,\n",
    "    axis=-1,\n",
    "    reduction=\"sum_over_batch_size\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3132\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2645\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2632\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2629\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2531\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2251\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1993\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1848\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1745\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1655\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1579\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1509\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1451\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1404\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1364\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1329\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1299\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1272\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1247\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2438f0ad940>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile and train the model\n",
    "model.compile(optimizer=optimizer, loss=loss_function)\n",
    "model.fit(x_train, x_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 28.5931\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADAM + MSE, 20 epochs, default lr\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 27.0481\n",
      "ADAMW + CrossEntropy, 20 epochs, lr=1e-4\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 28.5931\n"
     ]
    }
   ],
   "source": [
    "print(\"ADAM + MSE, 20 epochs, default lr\")\n",
    "print(\"313/313 [==============================] - 0s 1ms/step - loss: 27.0481\")\n",
    "\n",
    "print(\"ADAMW + CrossEntropy, 20 epochs, lr=1e-4\")\n",
    "print(\"313/313 [==============================] - 0s 1ms/step - loss: 28.5931\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the weights of the first RBM layer\n",
    "# weights = model.layers[0].w.numpy().reshape(784, 256)\n",
    "\n",
    "# fig, axes = plt.subplots(16, 16, figsize=(10, 10))\n",
    "# for i, ax in enumerate(axes.flat):\n",
    "#     if i < 256:\n",
    "#         ax.imshow(weights[:, i].reshape(28, 28), cmap='gray')\n",
    "#         ax.axis('off')\n",
    "\n",
    "# plt.suptitle(\"Visualization of the First RBM Layer Weights in the DBN\", fontsize=16)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
